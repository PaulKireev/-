***Содержание:

1  Подготовка данных
2  Исследование задачи
3  Борьба с дисбалансом
4  Тестирование модели
5  Чек-лист готовности проекта

***Отток клиентов:

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.
Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

***Описание данных:

Признаки:
* RowNumber — индекс строки в данных
* CustomerId — уникальный идентификатор клиента
* Surname — фамилия
* CreditScore — кредитный рейтинг
* Geography — страна проживания
* Gender — пол
* Age — возраст
* Tenure — сколько лет человек является клиентом банка
* Balance — баланс на счёте
* NumOfProducts — количество продуктов банка, используемых клиентом
* HasCrCard — наличие кредитной карты
* IsActiveMember — активность клиента
* EstimatedSalary — предполагаемая зарплата
Целевой признак:
* Exited — факт ухода клиента

***Общий вывод:

* Проведено прогнозирование оттока клиентов банка на основе исторических данных поведения клиентов.
* Построена модель с предельно большим значением F1-меры.
* В рамках подготовки данных скорректированы наименования полей, проанализированы выбросы и дубликаты, проработаны проработаны пропуски.
* Категориальные признаки переведены в дамми переменные.
* Для борьбы с дисбалансом использована техника upsampling, что позволило поднять показатель f1 в 4.5 раза. 
        Поэтому для дальнейшего прогноза были использованы данные features_upsampled, target_upsampled полученные с помощью техники upsampling.
* Проведен выбор лучшей модели для дальнейшего прогнозирования. Проанализированы модели LogisticRegression, DecisionTreeClassifier, RandomForestClassifier
* При сравнении базовых моделей, без дополнительных гиперпараметров, наилучший результат по F1 показала модель случайного леса. 
	Далее будем использовать её для подбора оптимальных гиперпараметров. 
  	Наилучший показаталь модель случайного леса на тестовой модели f1 = 0.599 при гиперпараметрах Глубина = 11 Количество деревьев = 100
* Проведена проверка модели на адекватность, путём сравнения со случайной моделью.
* Доля правильных ответов accuracy в полученной модели 0.822 Доля правильных ответов accuracy в случайной модели 0.7885
* Проверка на адекватность показала, что доля правильных ответов accuracy в полученной модели выше чем аналогичный показатель случайной модели.
	 Делаем вывод, что полученная нами модель является полезной.
* Дополнительно построена ROC - кривая, и измерена AUC-ROC = 0.8557